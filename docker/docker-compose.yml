services:
  mongo:
    image: mongo:6.0
    container_name: mongo
    command: ["--replSet", "rs0", "--bind_ip_all"]
    ports:
      - "27017:27017"
    healthcheck:
      test: ["CMD", "mongosh", "--quiet", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    restart: unless-stopped

  mongo-express:
    image: mongo-express:latest
    container_name: mongo-express
    depends_on:
      - mongo
    environment:
      ME_CONFIG_MONGODB_URL: mongodb://mongo:27017
      ME_CONFIG_BASICAUTH: "false"
    ports:
      - "8082:8081"
    restart: unless-stopped

  mongo-init-replica:
    image: mongo:6.0
    container_name: mongo-init-replica
    depends_on:
      mongo:
        condition: service_healthy
    entrypoint: ["sh", "-c", "mongosh --host mongo:27017 --quiet --eval 'rs.initiate({_id: \"rs0\", members: [{ _id: 0, host: \"mongo:27017\" }]})' || true"]
    restart: "no"

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    # volumes:
    #   - ./redis-data:/data
    # command: ["redis-server", "--appendonly", "yes"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_NUM_PARTITIONS: '1'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_METADATA_LOG_DIRS_CLEANUP_ENABLE: 'true'
      KAFKA_FORMAT_STORAGE_DIRS_ON_STARTUP: 'true'
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    hostname: kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: debezium
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    hostname: kafka-exporter
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "9308:9308"
    command:
      - --kafka.server=kafka:29092
     
      - --web.listen-address=0.0.0.0:9308
      # uncomment if SASL/TLS is needed and configure accordingly
      # - --sasl.enabled
      # - --sasl.username=...
      # - --sasl.password=...
    restart: unless-stopped

  jobmanager:
    build:
      context: ./flink
      dockerfile: Dockerfile
    container_name: flink-jobmanager
    ports:
      - "8081:8081"
      - "9249:9249"
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    command: jobmanager
    volumes:
      - ../flink-jobs/target:/opt/flink/jobs
      - ../flink-jobs/src/main/resources/config.yaml:/opt/flink/conf/config.yaml
    restart: unless-stopped
    depends_on:
      - kafka
  taskmanager:
    build:
      context: ./flink
      dockerfile: Dockerfile
    container_name: flink-taskmanager
    ports:
      - "9250:9249"
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - TASK_MANAGER_NUMBER_OF_TASK_SLOTS=4
    command: taskmanager
    restart: unless-stopped
    depends_on:
      - jobmanager
    volumes:
      - ../flink-jobs/result:/opt/flink/jobs
      - ../flink-jobs/src/main/resources/config.yaml:/opt/flink/conf/config.yaml
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    restart: unless-stopped
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_INSTALL_PLUGINS: grafana-clickhouse-datasource,redis-datasource
      GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS: grafana-clickhouse-datasource
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: "Admin"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    restart: unless-stopped

  data-generator:
    build:
      context: ../app-python
      dockerfile: Dockerfile
    hostname: data-generator
    depends_on:
      redis:
        condition: service_healthy
    environment:
      MONGO_URI: mongodb://mongo:27017
      MONGO_DB: leaderboard
      MONGO_COLLECTION: user_submissions
      LOG_LEVEL: INFO
      SLEEP_RATE: 10
    volumes:
      - ../app-python:/app
    working_dir: /app
    command: ["python", "_04_main.py", "replay-parquet-kafka"]
    # command: ["python", "_04_main.py", "start-producer"]
    # restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "print('ok')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

# volumes:
#   # Named volumes not required; using project-local bind mounts above
#   # Declare here only if you prefer Docker-managed volumes
#   # logs:
#   # notebook:
