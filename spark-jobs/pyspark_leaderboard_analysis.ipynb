{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PySpark Leaderboard Analysis - Local Mode\n",
        "\n",
        "Notebook này chạy PySpark ở local mode để gen snapshot leaderboard data từ parquet file.\n",
        "\n",
        "## Pipeline:\n",
        "1. Đọc data từ Parquet file\n",
        "2. Transform thành Score objects với event time\n",
        "3. Tính tổng điểm trong sliding window (5 phút gần nhất)\n",
        "4. Tính TopN với retraction logic\n",
        "5. Snapshot mỗi 7 phút theo event time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# check lại ttl time sau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime, timezone\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from dataclasses import dataclass\n",
        "from collections import defaultdict, deque\n",
        "import math\n",
        "\n",
        "# PySpark imports\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark version: 3.5.6\n",
            "Spark UI: http://localhost:4040\n",
            "Spark session created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initialize Spark Session for local mode\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"LeaderBoardAnalysis\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.skewJoin.enabled\", \"true\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(f\"Spark version: {spark.version}\")\n",
        "print(f\"Spark UI: http://localhost:4040\")\n",
        "print(\"Spark session created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# Helper functions\n",
        "def parse_timestamp(timestamp_str: str) -> int:\n",
        "    \"\"\"Parse timestamp string to milliseconds\"\"\"\n",
        "    try:\n",
        "        # Try parsing ISO format\n",
        "        dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))\n",
        "        return int(dt.timestamp() * 1000)\n",
        "    except:\n",
        "        # Fallback to current time\n",
        "        return int(datetime.now().timestamp() * 1000)\n",
        "\n",
        "def format_timestamp(timestamp: int) -> str:\n",
        "    \"\"\"Format timestamp for display\"\"\"\n",
        "    dt = datetime.fromtimestamp(timestamp / 1000, tz=timezone.utc)\n",
        "    return dt.isoformat()\n",
        "\n",
        "print(\"Helper functions defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading data from: fixed-dataset.parquet\n",
            "Data loaded successfully! Rows: 1000000\n",
            "+-------+-----+------------+-------+------+---+------------------------------------+--------------------------------+---------------+-------------------------------------------------------------------+---------+--------------------------------+--------------------------------+-----+-------------+--------------------------------+----+\n",
            "|uid    |email|authProvider|appId  |avatar|geo|role                                |lastLoginAt                     |name           |devices                                                            |resources|created_at                      |updated_at                      |level|previousLevel|updatedAt                       |team|\n",
            "+-------+-----+------------+-------+------+---+------------------------------------+--------------------------------+---------------+-------------------------------------------------------------------+---------+--------------------------------+--------------------------------+-----+-------------+--------------------------------+----+\n",
            "|user_2 |NULL |NULL        |app_001|14    |DE |15a0b246-737a-4807-8a78-06322b4886b6|2025-10-01T10:00:41.696918+00:00|Player 87258828|[{XHXBESBTLQNYWNSJPRPWBVSBWOXIKNAQ, QFoTYiICeVmLeHxPeuFvhp, empty}]|[]       |2025-10-01T10:00:41.696918+00:00|2025-10-01T10:00:41.696918+00:00|1    |0            |2025-10-01T10:00:41.696918+00:00|2   |\n",
            "|user_8 |NULL |NULL        |app_001|7     |UK |6edad0f5-4edf-43fd-a9d3-e0a9a8009e18|2025-10-01T10:00:41.797926+00:00|Player 36872638|[{WRRKFZSUFCZOZRDICPIKRVYQTHDTXUVW, pcNCWSqfhnxneAxirxQZFT, empty}]|[]       |2025-10-01T10:00:41.797926+00:00|2025-10-01T10:00:41.797926+00:00|6    |0            |2025-10-01T10:00:41.797926+00:00|3   |\n",
            "|user_8 |NULL |NULL        |app_001|7     |UK |6edad0f5-4edf-43fd-a9d3-e0a9a8009e18|2025-10-01T10:00:41.897926+00:00|Player 36872638|[{WRRKFZSUFCZOZRDICPIKRVYQTHDTXUVW, pcNCWSqfhnxneAxirxQZFT, empty}]|[]       |2025-10-01T10:00:41.897926+00:00|2025-10-01T10:00:41.897926+00:00|15   |6            |2025-10-01T10:00:41.897926+00:00|3   |\n",
            "|user_4 |NULL |NULL        |app_001|4     |DE |024b13af-f815-4aef-9226-ba236a90de04|2025-10-01T10:00:41.997926+00:00|Player 90024503|[{EJNZVSLGIPDWNPROUVYAACDBPUOLCJPU, cjRNwAEMAmETijXilgPzAX, empty}]|[]       |2025-10-01T10:00:41.997926+00:00|2025-10-01T10:00:41.997926+00:00|1    |0            |2025-10-01T10:00:41.997926+00:00|8   |\n",
            "|user_14|NULL |NULL        |app_001|4     |FR |4dd0b288-1400-4992-8fbe-5684f223cd8d|2025-10-01T10:00:42.097926+00:00|Player 74214278|[{YRIRAFIRFZVTLSJAVCKJOKAUTSYFUWOP, PKGYqNZyftgRDieaLIsyDA, empty}]|[]       |2025-10-01T10:00:42.097926+00:00|2025-10-01T10:00:42.097926+00:00|1    |0            |2025-10-01T10:00:42.097926+00:00|10  |\n",
            "|user_16|NULL |NULL        |app_001|5     |JP |4160ee00-6a93-41e7-be6b-d29bb647c5aa|2025-10-01T10:00:42.197926+00:00|Player 90406198|[{HMPCEDEJMPCAXVCPXVEBYDCOXMLQAJMS, PARSQhjfVQEsRPfVzwapxe, empty}]|[]       |2025-10-01T10:00:42.197926+00:00|2025-10-01T10:00:42.197926+00:00|3    |0            |2025-10-01T10:00:42.197926+00:00|9   |\n",
            "|user_20|NULL |NULL        |app_001|8     |UK |f045119d-fbae-4a7f-b5e7-b79b69b37fb0|2025-10-01T10:00:42.297926+00:00|Player 49339065|[{LNIXPSJRKMYXMFKAPQBHTKJTNROLFNHS, UWMTKvVGKcDpsHYyzycEpp, empty}]|[]       |2025-10-01T10:00:42.297926+00:00|2025-10-01T10:00:42.297926+00:00|4    |0            |2025-10-01T10:00:42.297926+00:00|4   |\n",
            "|user_20|NULL |NULL        |app_001|8     |UK |f045119d-fbae-4a7f-b5e7-b79b69b37fb0|2025-10-01T10:00:42.397926+00:00|Player 49339065|[{LNIXPSJRKMYXMFKAPQBHTKJTNROLFNHS, UWMTKvVGKcDpsHYyzycEpp, empty}]|[]       |2025-10-01T10:00:42.397926+00:00|2025-10-01T10:00:42.397926+00:00|6    |4            |2025-10-01T10:00:42.397926+00:00|4   |\n",
            "|user_16|NULL |NULL        |app_001|5     |JP |4160ee00-6a93-41e7-be6b-d29bb647c5aa|2025-10-01T10:00:42.497926+00:00|Player 90406198|[{HMPCEDEJMPCAXVCPXVEBYDCOXMLQAJMS, PARSQhjfVQEsRPfVzwapxe, empty}]|[]       |2025-10-01T10:00:42.497926+00:00|2025-10-01T10:00:42.497926+00:00|5    |3            |2025-10-01T10:00:42.497926+00:00|9   |\n",
            "|user_20|NULL |NULL        |app_001|8     |UK |f045119d-fbae-4a7f-b5e7-b79b69b37fb0|2025-10-01T10:00:42.597926+00:00|Player 49339065|[{LNIXPSJRKMYXMFKAPQBHTKJTNROLFNHS, UWMTKvVGKcDpsHYyzycEpp, empty}]|[]       |2025-10-01T10:00:42.597926+00:00|2025-10-01T10:00:42.597926+00:00|14   |6            |2025-10-01T10:00:42.597926+00:00|4   |\n",
            "+-------+-----+------------+-------+------+---+------------------------------------+--------------------------------+---------------+-------------------------------------------------------------------+---------+--------------------------------+--------------------------------+-----+-------------+--------------------------------+----+\n",
            "only showing top 10 rows\n",
            "\n",
            "root\n",
            " |-- uid: string (nullable = true)\n",
            " |-- email: string (nullable = true)\n",
            " |-- authProvider: string (nullable = true)\n",
            " |-- appId: string (nullable = true)\n",
            " |-- avatar: string (nullable = true)\n",
            " |-- geo: string (nullable = true)\n",
            " |-- role: string (nullable = true)\n",
            " |-- lastLoginAt: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- devices: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- fb_analytics_instance_id: string (nullable = true)\n",
            " |    |    |-- fb_instance_id: string (nullable = true)\n",
            " |    |    |-- fcmToken: string (nullable = true)\n",
            " |-- resources: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- updated_at: string (nullable = true)\n",
            " |-- level: long (nullable = true)\n",
            " |-- previousLevel: long (nullable = true)\n",
            " |-- updatedAt: string (nullable = true)\n",
            " |-- team: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Read data from Parquet file\n",
        "input_path = \"fixed-dataset.parquet\"\n",
        "\n",
        "if os.path.exists(input_path):\n",
        "    print(f\"Reading data from: {input_path}\")\n",
        "    user_data = spark.read.parquet(input_path)\n",
        "    print(f\"Data loaded successfully! Rows: {user_data.count()}\")\n",
        "    user_data.show(10, False)\n",
        "    user_data.printSchema()\n",
        "else:\n",
        "    print(f\"File not found: {input_path}\")\n",
        "    print(\"Available files in app-python directory:\")\n",
        "    if os.path.exists(\"app-python\"):\n",
        "        for file in os.listdir(\"app-python\"):\n",
        "            print(f\"  - {file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|uid   |level|\n",
            "+------+-----+\n",
            "|user_1|2    |\n",
            "|user_1|3    |\n",
            "|user_1|7    |\n",
            "|user_1|8    |\n",
            "|user_1|12   |\n",
            "|user_1|16   |\n",
            "|user_1|24   |\n",
            "|user_1|26   |\n",
            "|user_1|29   |\n",
            "|user_1|30   |\n",
            "|user_1|39   |\n",
            "|user_1|47   |\n",
            "|user_1|48   |\n",
            "|user_1|50   |\n",
            "|user_1|57   |\n",
            "|user_1|64   |\n",
            "|user_1|65   |\n",
            "|user_1|73   |\n",
            "|user_1|82   |\n",
            "|user_1|84   |\n",
            "|user_1|89   |\n",
            "|user_1|91   |\n",
            "|user_1|95   |\n",
            "|user_1|97   |\n",
            "|user_1|99   |\n",
            "|user_1|106  |\n",
            "|user_1|111  |\n",
            "|user_1|116  |\n",
            "|user_1|118  |\n",
            "|user_1|122  |\n",
            "|user_1|123  |\n",
            "|user_1|128  |\n",
            "|user_1|129  |\n",
            "|user_1|133  |\n",
            "|user_1|143  |\n",
            "|user_1|153  |\n",
            "|user_1|157  |\n",
            "|user_1|160  |\n",
            "|user_1|161  |\n",
            "|user_1|169  |\n",
            "|user_1|173  |\n",
            "|user_1|175  |\n",
            "|user_1|182  |\n",
            "|user_1|190  |\n",
            "|user_1|195  |\n",
            "|user_1|204  |\n",
            "|user_1|207  |\n",
            "|user_1|208  |\n",
            "|user_1|209  |\n",
            "|user_1|213  |\n",
            "|user_1|214  |\n",
            "|user_1|217  |\n",
            "|user_1|219  |\n",
            "|user_1|220  |\n",
            "|user_1|221  |\n",
            "|user_1|222  |\n",
            "|user_1|223  |\n",
            "|user_1|230  |\n",
            "|user_1|233  |\n",
            "|user_1|241  |\n",
            "|user_1|244  |\n",
            "|user_1|249  |\n",
            "|user_1|250  |\n",
            "|user_1|252  |\n",
            "|user_1|257  |\n",
            "|user_1|265  |\n",
            "|user_1|266  |\n",
            "|user_1|267  |\n",
            "|user_1|269  |\n",
            "|user_1|272  |\n",
            "|user_1|274  |\n",
            "|user_1|282  |\n",
            "|user_1|288  |\n",
            "|user_1|289  |\n",
            "|user_1|290  |\n",
            "|user_1|297  |\n",
            "|user_1|302  |\n",
            "|user_1|304  |\n",
            "|user_1|310  |\n",
            "|user_1|313  |\n",
            "|user_1|314  |\n",
            "|user_1|315  |\n",
            "|user_1|319  |\n",
            "|user_1|326  |\n",
            "|user_1|335  |\n",
            "|user_1|337  |\n",
            "|user_1|338  |\n",
            "|user_1|340  |\n",
            "|user_1|347  |\n",
            "|user_1|350  |\n",
            "|user_1|351  |\n",
            "|user_1|353  |\n",
            "|user_1|355  |\n",
            "|user_1|356  |\n",
            "|user_1|359  |\n",
            "|user_1|361  |\n",
            "|user_1|362  |\n",
            "|user_1|366  |\n",
            "|user_1|367  |\n",
            "|user_1|368  |\n",
            "+------+-----+\n",
            "only showing top 100 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# In ra 100 hàng đầu filter theo userId = 1\n",
        "user_data.filter(col(\"uid\") == \"user_1\").select(\"uid\", \"level\").show(100, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+--------------+\n",
            "|id     |score|lastUpdateTime|\n",
            "+-------+-----+--------------+\n",
            "|user_2 |1    |1759312841696 |\n",
            "|user_8 |6    |1759312841797 |\n",
            "|user_8 |9    |1759312841897 |\n",
            "|user_4 |1    |1759312841997 |\n",
            "|user_14|1    |1759312842097 |\n",
            "|user_16|3    |1759312842197 |\n",
            "|user_20|4    |1759312842297 |\n",
            "|user_20|2    |1759312842397 |\n",
            "|user_16|2    |1759312842497 |\n",
            "|user_20|8    |1759312842597 |\n",
            "|user_15|2    |1759312842697 |\n",
            "|user_17|3    |1759312842797 |\n",
            "|user_19|8    |1759312842897 |\n",
            "|user_9 |10   |1759312842997 |\n",
            "|user_17|2    |1759312843097 |\n",
            "|user_5 |2    |1759312843197 |\n",
            "|user_20|2    |1759312843297 |\n",
            "|user_14|7    |1759312843397 |\n",
            "|user_10|1    |1759312843497 |\n",
            "|user_11|5    |1759312843597 |\n",
            "+-------+-----+--------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "user_scores = user_data.select(\n",
        "    col(\"uid\").alias(\"id\"),\n",
        "    when(col(\"level\") - col(\"previousLevel\") > 0, \n",
        "           col(\"level\") - col(\"previousLevel\"))\n",
        "     .otherwise(0).alias(\"score\"),\n",
        "    ((to_timestamp(col(\"updatedAt\")).cast(\"timestamp\").cast(\"double\") * 1000).cast(\"long\").alias(\"lastUpdateTime\"))\n",
        "  \n",
        ")\n",
        "print(user_scores.show(n=20, truncate=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating sliding window scores for 1 minute window...\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Calculate total scores in sliding window \n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import sum as spark_sum, lag, col, when\n",
        "\n",
        "window_size_minutes = 1\n",
        "window_size_ms = window_size_minutes * 60 * 1000\n",
        "\n",
        "print(f\"Calculating sliding window scores for {window_size_minutes} minute window...\")\n",
        "\n",
        "# Create window specification for sliding window calculation\n",
        "window_spec = Window.partitionBy(\"id\").orderBy(\"lastUpdateTime\")\n",
        "\n",
        "# Calculate total score in sliding window using rangeBetween\n",
        "total_scores = user_scores.withColumn(\n",
        "    \"totalScore\",\n",
        "    spark_sum(\"score\").over(\n",
        "        window_spec.rangeBetween(-window_size_ms, 0)\n",
        "    )\n",
        ").withColumn(\n",
        "    \"previousTotalScore\",\n",
        "    lag(\"totalScore\", 1, 0.0).over(window_spec)\n",
        ").select(\n",
        "    col(\"id\").alias(\"userId\"),\n",
        "    col(\"totalScore\"),\n",
        "    col(\"previousTotalScore\"),\n",
        "    col(\"lastUpdateTime\")\n",
        ")\n",
        "\n",
        "print(\"done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total scores calculated for 1 minute window!\n",
            "+------+----------+------------------+--------------+\n",
            "|userId|totalScore|previousTotalScore|lastUpdateTime|\n",
            "+------+----------+------------------+--------------+\n",
            "|user_1|2         |0                 |1759312851398 |\n",
            "|user_1|3         |2                 |1759312853598 |\n",
            "|user_1|7         |3                 |1759312856198 |\n",
            "|user_1|8         |7                 |1759312857099 |\n",
            "|user_1|12        |8                 |1759312857499 |\n",
            "|user_1|16        |12                |1759312861399 |\n",
            "|user_1|24        |16                |1759312863399 |\n",
            "|user_1|26        |24                |1759312863499 |\n",
            "|user_1|29        |26                |1759312866800 |\n",
            "|user_1|30        |29                |1759312875400 |\n",
            "|user_1|39        |30                |1759312876000 |\n",
            "|user_1|47        |39                |1759312877300 |\n",
            "|user_1|48        |47                |1759312879202 |\n",
            "|user_1|50        |48                |1759312881902 |\n",
            "|user_1|57        |50                |1759312884202 |\n",
            "|user_1|64        |57                |1759312885402 |\n",
            "|user_1|65        |64                |1759312885502 |\n",
            "|user_1|73        |65                |1759312889702 |\n",
            "|user_1|82        |73                |1759312893703 |\n",
            "|user_1|84        |82                |1759312894103 |\n",
            "|user_1|89        |84                |1759312894203 |\n",
            "|user_1|91        |89                |1759312895403 |\n",
            "|user_1|95        |91                |1759312896903 |\n",
            "|user_1|97        |95                |1759312897803 |\n",
            "|user_1|99        |97                |1759312898003 |\n",
            "|user_1|106       |99                |1759312898503 |\n",
            "|user_1|111       |106               |1759312899603 |\n",
            "|user_1|116       |111               |1759312901103 |\n",
            "|user_1|118       |116               |1759312903904 |\n",
            "|user_1|122       |118               |1759312904004 |\n",
            "|user_1|123       |122               |1759312905604 |\n",
            "|user_1|128       |123               |1759312906404 |\n",
            "|user_1|117       |128               |1759312917905 |\n",
            "|user_1|121       |117               |1759312918305 |\n",
            "|user_1|131       |121               |1759312920205 |\n",
            "|user_1|141       |131               |1759312921205 |\n",
            "|user_1|141       |141               |1759312922806 |\n",
            "|user_1|131       |141               |1759312929806 |\n",
            "|user_1|132       |131               |1759312931906 |\n",
            "|user_1|140       |132               |1759312933406 |\n",
            "|user_1|144       |140               |1759312933906 |\n",
            "|user_1|136       |144               |1759312936507 |\n",
            "|user_1|143       |136               |1759312936707 |\n",
            "|user_1|143       |143               |1759312939107 |\n",
            "|user_1|147       |143               |1759312939807 |\n",
            "|user_1|154       |147               |1759312943507 |\n",
            "|user_1|150       |154               |1759312944307 |\n",
            "|user_1|151       |150               |1759312944407 |\n",
            "|user_1|152       |151               |1759312944907 |\n",
            "|user_1|148       |152               |1759312948807 |\n",
            "|user_1|149       |148               |1759312949407 |\n",
            "|user_1|144       |149               |1759312950707 |\n",
            "|user_1|146       |144               |1759312951207 |\n",
            "|user_1|147       |146               |1759312951307 |\n",
            "|user_1|148       |147               |1759312951507 |\n",
            "|user_1|149       |148               |1759312952507 |\n",
            "|user_1|150       |149               |1759312952907 |\n",
            "|user_1|157       |150               |1759312953208 |\n",
            "|user_1|144       |157               |1759312955308 |\n",
            "|user_1|150       |144               |1759312956808 |\n",
            "|user_1|149       |150               |1759312957708 |\n",
            "|user_1|150       |149               |1759312958308 |\n",
            "|user_1|139       |150               |1759312960208 |\n",
            "|user_1|136       |139               |1759312961108 |\n",
            "|user_1|141       |136               |1759312961208 |\n",
            "|user_1|149       |141               |1759312961508 |\n",
            "|user_1|144       |149               |1759312964008 |\n",
            "|user_1|139       |144               |1759312967509 |\n",
            "|user_1|141       |139               |1759312967909 |\n",
            "|user_1|144       |141               |1759312968909 |\n",
            "|user_1|146       |144               |1759312969009 |\n",
            "|user_1|154       |146               |1759312969709 |\n",
            "|user_1|160       |154               |1759312970609 |\n",
            "|user_1|161       |160               |1759312972109 |\n",
            "|user_1|162       |161               |1759312973809 |\n",
            "|user_1|169       |162               |1759312977009 |\n",
            "|user_1|159       |169               |1759312980510 |\n",
            "|user_1|147       |159               |1759312983110 |\n",
            "|user_1|153       |147               |1759312984110 |\n",
            "|user_1|156       |153               |1759312984610 |\n",
            "|user_1|157       |156               |1759312986010 |\n",
            "|user_1|158       |157               |1759312986810 |\n",
            "|user_1|162       |158               |1759312987110 |\n",
            "|user_1|169       |162               |1759312987810 |\n",
            "|user_1|178       |169               |1759312987910 |\n",
            "|user_1|177       |178               |1759312990110 |\n",
            "|user_1|178       |177               |1759312991211 |\n",
            "|user_1|180       |178               |1759312991611 |\n",
            "|user_1|174       |180               |1759312994211 |\n",
            "|user_1|177       |174               |1759312996111 |\n",
            "|user_1|147       |177               |1759313004212 |\n",
            "|user_1|144       |147               |1759313007213 |\n",
            "|user_1|142       |144               |1759313009313 |\n",
            "|user_1|142       |142               |1759313010213 |\n",
            "|user_1|139       |142               |1759313011313 |\n",
            "|user_1|131       |139               |1759313013813 |\n",
            "|user_1|129       |131               |1759313016213 |\n",
            "|user_1|125       |129               |1759313017213 |\n",
            "|user_1|126       |125               |1759313017413 |\n",
            "|user_1|119       |126               |1759313018413 |\n",
            "+------+----------+------------------+--------------+\n",
            "only showing top 100 rows\n",
            "\n",
            "Total records: 1000000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total scores calculated for {window_size_minutes} minute window!\")\n",
        "total_scores.filter(col(\"userId\") == \"user_1\").show(100, False)\n",
        "print(f\"Total records: {total_scores.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_leaderboard_at_snapshot(total_scores: DataFrame, snapshot_time: int, \n",
        "                                    top_n: int, cutoff_time: int) -> List[LeaderBoardEntry]:\n",
        "\n",
        "    \n",
        "   \n",
        "    \n",
        "    print(f\"  Snapshot at {format_timestamp(snapshot_time)}: using data from {format_timestamp(cutoff_time)} to {format_timestamp(snapshot_time)}\")\n",
        "    \n",
        "\n",
        "    valid_scores = total_scores.filter(\n",
        "        (col('lastUpdateTime') <= snapshot_time) & \n",
        "        (col('lastUpdateTime') > cutoff_time)\n",
        "    ).collect()\n",
        "    \n",
        "    print(f\"    Found {len(valid_scores)} valid scores in cleanup interval\")\n",
        "    \n",
        "    # Group by user và lấy score mới nhất cho mỗi user\n",
        "    user_latest_scores = {}\n",
        "    for score in valid_scores:\n",
        "        user_id = score['userId']\n",
        "        if user_id not in user_latest_scores or score['lastUpdateTime'] > user_latest_scores[user_id]['lastUpdateTime']:\n",
        "            user_latest_scores[user_id] = score\n",
        "    \n",
        "    print(f\"    Found {len(user_latest_scores)} unique users\")\n",
        "    \n",
        "    # Sort by total score và lấy top N\n",
        "    sorted_users = sorted(user_latest_scores.values(), key=lambda x: x['totalScore'], reverse=True)\n",
        "    \n",
        "    # Tạo leaderboard entries cho snapshot này\n",
        "    snapshot_entries = []\n",
        "    for i, user_score in enumerate(sorted_users[:top_n]):\n",
        "        snapshot_entries.append(LeaderBoardEntry(\n",
        "            userId=user_score['userId'],\n",
        "            totalScore=user_score['totalScore'],\n",
        "            rank=i + 1,\n",
        "            lastUpdateTime=user_score['lastUpdateTime'],\n",
        "            snapshotTime=snapshot_time\n",
        "        ))\n",
        "    \n",
        "    print(f\"    Generated {len(snapshot_entries)} leaderboard entries (Top-{top_n})\")\n",
        "    return snapshot_entries\n",
        "\n",
        "def generate_snapshots_with_retractable_logic(total_scores: DataFrame, top_n: int, \n",
        "                                            cleanup_interval_minutes: int = 5,\n",
        "                                            snapshot_interval_minutes: int = 7) -> List[LeaderBoardEntry]:\n",
        "    \"\"\"Generate snapshots với logic retractable TopN đúng\"\"\"\n",
        "    \n",
        "    # Lấy tất cả timestamps\n",
        "    all_timestamps = [row['lastUpdateTime'] for row in total_scores.select('lastUpdateTime').distinct().collect()]\n",
        "    all_timestamps.sort()\n",
        "    \n",
        "    if not all_timestamps:\n",
        "        return []\n",
        "    \n",
        "    first_timestamp = all_timestamps[0]\n",
        "    last_timestamp = all_timestamps[-1]\n",
        "    \n",
        "    # Convert intervals to milliseconds\n",
        "    snapshot_interval_ms = snapshot_interval_minutes * 60 * 1000\n",
        "    cleanup_interval_ms = cleanup_interval_minutes * 60 * 1000\n",
        "    \n",
        "    print(f\"Data range: {format_timestamp(first_timestamp)} to {format_timestamp(last_timestamp)}\")\n",
        "    print(f\"Cleanup interval: {cleanup_interval_minutes} minutes\")\n",
        "    print(f\"Snapshot interval: {snapshot_interval_minutes} minutes\")\n",
        "    \n",
        "    # Generate snapshot times\n",
        "    snapshot_times = []\n",
        "    current_snapshot_time = first_timestamp + snapshot_interval_ms\n",
        "    \n",
        "    while current_snapshot_time <= last_timestamp:\n",
        "        snapshot_times.append(current_snapshot_time)\n",
        "        current_snapshot_time += snapshot_interval_ms\n",
        "    \n",
        "    print(f\"\\nGenerated {len(snapshot_times)} snapshot times:\")\n",
        "    for i, ts in enumerate(snapshot_times):\n",
        "        print(f\"  Snapshot {i+1}: {format_timestamp(ts)}\")\n",
        "    \n",
        "    # Generate cleanup times để debug\n",
        "    cleanup_times = []\n",
        "    # Cleanup đầu tiên = first_timestamp + cleanup_interval_ms * 2 (như trong Flink code)\n",
        "    first_cleanup_time = first_timestamp + cleanup_interval_ms * 2\n",
        "    current_cleanup_time = first_cleanup_time\n",
        "    \n",
        "    while current_cleanup_time <= last_timestamp:\n",
        "        cleanup_times.append(current_cleanup_time)\n",
        "        current_cleanup_time += cleanup_interval_ms\n",
        "    \n",
        "    print(f\"\\nCleanup times (for reference):\")\n",
        "    for i, ts in enumerate(cleanup_times[:10]):  # Show first 10\n",
        "        print(f\"  Cleanup {i+1}: {format_timestamp(ts)}\")\n",
        "    if len(cleanup_times) > 10:\n",
        "        print(f\"  ... and {len(cleanup_times) - 10} more\")\n",
        "\n",
        "    \n",
        "    # Tính leaderboard tại các snapshot times\n",
        "    all_snapshots = []\n",
        "    # Sử dụng bisect để tìm cleanup_time lớn nhất mà < snapshot_time một cách hiệu quả\n",
        "    import bisect\n",
        "\n",
        "    cleanup_times_sorted = sorted(cleanup_times)\n",
        "    for i, snapshot_time in enumerate(snapshot_times):\n",
        "        # Tìm vị trí chèn snapshot_time vào cleanup_times_sorted\n",
        "        idx = bisect.bisect_left(cleanup_times_sorted, snapshot_time)\n",
        "        cutoff_time = (\n",
        "            cleanup_times_sorted[0] - cleanup_interval_ms if idx == 1\n",
        "            else cleanup_times_sorted[idx-2] if idx > 1\n",
        "            else first_timestamp\n",
        "        )\n",
        "\n",
        "        snapshot_entries = calculate_leaderboard_at_snapshot(\n",
        "            total_scores, snapshot_time, top_n, cutoff_time\n",
        "        )\n",
        "        all_snapshots.extend(snapshot_entries)\n",
        "    \n",
        "    return all_snapshots\n",
        "\n",
        "print(\"Retractable TopN snapshot functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Generate leaderboard snapshots\n",
        "top_n = 10\n",
        "ttl_minutes = 30\n",
        "snapshot_interval_minutes = 7\n",
        "\n",
        "print(f\"Generating leaderboard snapshots with:\")\n",
        "print(f\"  Top N: {top_n}\")\n",
        "print(f\"  TTL: {ttl_minutes} minutes\")\n",
        "print(f\"  Snapshot interval: {snapshot_interval_minutes} minutes\")\n",
        "\n",
        "snapshots = generate_snapshots(\n",
        "    total_scores, \n",
        "    top_n, \n",
        "    ttl_minutes, \n",
        "    snapshot_interval_minutes\n",
        ")\n",
        "\n",
        "print(f\"\\nGenerated {len(snapshots)} leaderboard entries across snapshots.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: Display results\n",
        "if snapshots:\n",
        "    # Convert to DataFrame for better display\n",
        "    snapshot_data = []\n",
        "    for entry in snapshots:\n",
        "        snapshot_data.append({\n",
        "            'userId': entry.userId,\n",
        "            'totalScore': entry.totalScore,\n",
        "            'rank': entry.rank,\n",
        "            'lastUpdateTime': entry.lastUpdateTime,\n",
        "            'snapshotTime': entry.snapshotTime,\n",
        "            'snapshotTimeFormatted': format_timestamp(entry.snapshotTime),\n",
        "            'lastUpdateTimeFormatted': format_timestamp(entry.lastUpdateTime)\n",
        "        })\n",
        "    \n",
        "    snapshot_df = spark.createDataFrame(snapshot_data)\n",
        "    \n",
        "    print(\"\\n=== LEADERBOARD SNAPSHOTS ===\")\n",
        "    snapshot_df.orderBy(\"snapshotTime\", \"rank\").show(50, False)\n",
        "    \n",
        "    # Show summary by snapshot time\n",
        "    print(\"\\n=== SNAPSHOT SUMMARY ===\")\n",
        "    snapshot_summary = snapshot_df.groupBy(\"snapshotTimeFormatted\") \\\n",
        "        .agg(\n",
        "            count(\"userId\").alias(\"userCount\"),\n",
        "            max(\"totalScore\").alias(\"maxScore\"),\n",
        "            min(\"totalScore\").alias(\"minScore\"),\n",
        "            avg(\"totalScore\").alias(\"avgScore\")\n",
        "        ) \\\n",
        "        .orderBy(\"snapshotTimeFormatted\")\n",
        "    \n",
        "    snapshot_summary.show(20, False)\n",
        "    \n",
        "    # Show top users across all snapshots\n",
        "    print(\"\\n=== TOP USERS ACROSS ALL SNAPSHOTS ===\")\n",
        "    top_users = snapshot_df.groupBy(\"userId\") \\\n",
        "        .agg(\n",
        "            count(\"rank\").alias(\"snapshotCount\"),\n",
        "            max(\"totalScore\").alias(\"maxScore\"),\n",
        "            avg(\"totalScore\").alias(\"avgScore\"),\n",
        "            min(\"rank\").alias(\"bestRank\")\n",
        "        ) \\\n",
        "        .orderBy(desc(\"maxScore\"), desc(\"avgScore\"))\n",
        "    \n",
        "    top_users.show(20, False)\n",
        "    \n",
        "else:\n",
        "    print(\"No snapshots generated!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Save results to file\n",
        "output_path = \"spark-jobs/result/leaderboard_snapshots\"\n",
        "\n",
        "if snapshots:\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    \n",
        "    # Write as JSON with partitioning by snapshot time\n",
        "    snapshot_df.write \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .partitionBy(\"snapshotTime\") \\\n",
        "        .json(output_path)\n",
        "    \n",
        "    print(f\"Snapshots saved to: {output_path}\")\n",
        "    \n",
        "    # Also save as CSV for easier viewing\n",
        "    csv_path = \"spark-jobs/result/leaderboard_snapshots.csv\"\n",
        "    snapshot_df.coalesce(1).write \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .option(\"header\", \"true\") \\\n",
        "        .csv(csv_path)\n",
        "    \n",
        "    print(f\"CSV version saved to: {csv_path}\")\n",
        "else:\n",
        "    print(\"No snapshots to save!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: Performance analysis\n",
        "print(\"\\n=== PERFORMANCE ANALYSIS ===\")\n",
        "print(f\"Total user data records: {user_data.count()}\")\n",
        "print(f\"Total score records: {scores.count()}\")\n",
        "print(f\"Total calculated scores: {total_scores.count()}\")\n",
        "print(f\"Total leaderboard entries: {len(snapshots)}\")\n",
        "\n",
        "if snapshots:\n",
        "    unique_users = len(set(entry.userId for entry in snapshots))\n",
        "    unique_snapshots = len(set(entry.snapshotTime for entry in snapshots))\n",
        "    \n",
        "    print(f\"Unique users in leaderboard: {unique_users}\")\n",
        "    print(f\"Unique snapshot times: {unique_snapshots}\")\n",
        "    \n",
        "    # Calculate average users per snapshot\n",
        "    avg_users_per_snapshot = len(snapshots) / unique_snapshots if unique_snapshots > 0 else 0\n",
        "    print(f\"Average users per snapshot: {avg_users_per_snapshot:.2f}\")\n",
        "\n",
        "print(\"\\n=== ANALYSIS COMPLETED ===\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up\n",
        "print(\"Stopping Spark session...\")\n",
        "spark.stop()\n",
        "print(\"Spark session stopped successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
